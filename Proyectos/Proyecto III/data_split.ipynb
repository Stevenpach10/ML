{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd009cf3d5909f3828bf53c46564821f879a9c8405e40e27fb09b54d745264e4a6d",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Required imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "source": [
    "### Misc functions used to validate and save the split of the raw data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to validate the distribution of the split.\n",
    "def validateSplit(noLabelSet, labelTrainingSet, labelTestingSet, classNames):\n",
    "    classAmount = len(classNames)\n",
    "\n",
    "    # Arrays to store the amount of samples of each class.\n",
    "    noLabelDist       = np.array([0] * classAmount)\n",
    "    labelTrainingDist = np.array([0] * classAmount)\n",
    "    labelTestingDist  = np.array([0] * classAmount)\n",
    "\n",
    "    # Count the samples of each class in the no labels set.\n",
    "    for sample in noLabelSet:\n",
    "        noLabelDist[sample[1]] += 1\n",
    "\n",
    "    # Count the samples of each class in the labels training set.\n",
    "    for sample in labelTrainingSet:\n",
    "        labelTrainingDist[sample[1]] += 1\n",
    "\n",
    "    # Count the samples of each class in the labels testing set.\n",
    "    for sample in labelTestingSet:\n",
    "        labelTestingDist[sample[1]] += 1\n",
    "\n",
    "    # Make the distribution vector (percentages of each class).\n",
    "    noLabelProb       = noLabelDist / len(noLabelSet) * 100\n",
    "    labelTrainingProb = labelTrainingDist / len(labelTrainingSet) * 100\n",
    "    labelTestingProb  = labelTestingDist / len(labelTestingSet) * 100\n",
    "\n",
    "    # Print the distributions.\n",
    "    tableSep = \"+{0}+{1}+{1}+{1}+\".format('-' * 52, '-' * 14)\n",
    "    tableCell = \"{0:>4} ({1:2.2f}%)\"\n",
    "    tableLine = \"| {0:>50} | {1:<12} | {2:<12} | {3:<12} |\"\n",
    "\n",
    "    print('Class distribution of each set')\n",
    "    print(tableSep)\n",
    "    print(tableLine.format('Class name', 'No label', 'Training', 'Testing'))\n",
    "    print(tableSep)\n",
    "    for i in range(classAmount):\n",
    "        noLabelStr       = tableCell.format(noLabelDist[i], noLabelProb[i])\n",
    "        labelTrainingStr = tableCell.format(labelTrainingDist[i], labelTrainingProb[i])\n",
    "        labelTestingStr  = tableCell.format(labelTestingDist[i], labelTestingProb[i])\n",
    "        print(tableLine.format(classNames[i], noLabelStr, labelTrainingStr, labelTestingStr))\n",
    "    print(tableSep)\n",
    "\n",
    "# Function used to save a split based on a type (training or testing).\n",
    "def saveSplit(dataset, classNames, setType, path):\n",
    "    # Get the dir for each class.\n",
    "    dirs = [os.path.join(os.getcwd(), path, setType, className) for className in classNames]\n",
    "\n",
    "    # Make the dirs.\n",
    "    for _dir in dirs:\n",
    "        Path(_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Array for control the name of the files.\n",
    "    classCounter = np.array([0] * len(classNames))\n",
    "\n",
    "    # For printing the progress.\n",
    "    samplesProcessed = 0\n",
    "    samplesStep = 25\n",
    "    step = len(dataset) // 4\n",
    "\n",
    "    # Each set can be iterated getting tuples of (PIL image, label).\n",
    "    for sample in dataset:\n",
    "        # Unpack the sample.\n",
    "        (image, label) = sample\n",
    "        # Save the image in the corresponding dir.\n",
    "        image.save(os.path.join(dirs[label], str(classCounter[label]) + '.png'))\n",
    "        # Increment the counter.\n",
    "        classCounter[label] += 1\n",
    "        \n",
    "        # Progress printing.\n",
    "        samplesProcessed += 1\n",
    "        if (samplesProcessed % step == 0):\n",
    "            print('\\t' + str(samplesStep) + '% saved.')\n",
    "            samplesStep += 25\n",
    "\n",
    "# Function used to save the splits.\n",
    "def saveSplits(noLabelSet, labelTrainingSet, labelTestingSet, classNames, path):\n",
    "    print('Saving no labels set')\n",
    "    rawTrainDir = saveSplit(noLabelSet, classNames, 'noLabel', path)\n",
    "    print()\n",
    "\n",
    "    print('Saving labels training set')\n",
    "    rawTestDir = saveSplit(labelTrainingSet, classNames, 'labelTrain', path)\n",
    "    print()\n",
    "\n",
    "    print('Saving labels testing set')\n",
    "    rawTestDir = saveSplit(labelTestingSet, classNames, 'labelTest', path)"
   ]
  },
  {
   "source": [
    "### Split data\n",
    "Function to get the raw data and separate them in a no label, label training, label testing set and save them. In order to maintain the same sets for all the runs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSplits(datasetPath, noLabelPercentage, labelTrainingPercentage, labelTestingPercentage, outputPath):\n",
    "    print('/* Making the split *\\\\')\n",
    "\n",
    "    # Get the raw dataset.\n",
    "    dataset = ImageFolder(datasetPath)\n",
    "    classNames = dataset.classes\n",
    "\n",
    "    # Get the size of the no label set, label set for training and label set for testing.\n",
    "    noLabelLen        = int(len(dataset) * noLabelPercentage)\n",
    "    labelTrainingLen  = int(len(dataset) * labelTrainingPercentage)\n",
    "    labelTestingLen   = len(dataset) - noLabelLen - labelTrainingLen\n",
    "\n",
    "    print('Len of the dataset:', len(dataset))\n",
    "    print('Set distribution:')\n",
    "    print('\\t      No labels set: {0} ({1:2.2f}%)'.format(noLabelLen, noLabelLen / len(dataset) * 100))\n",
    "    print('\\tLabels training set: {0} ({1:2.2f}%)'.format(labelTrainingLen, labelTrainingLen / len(dataset) * 100))\n",
    "    print('\\t Labels testing set: {0} ({1:2.2f}%)'.format(labelTestingLen, labelTestingLen / len(dataset) * 100))\n",
    "\n",
    "    # Random split the general dataset.\n",
    "    noLabelSet, labelTrainingSet, labelTestingSet = random_split(dataset, [noLabelLen, labelTrainingLen, labelTestingLen])\n",
    "\n",
    "    # Validate the splits.\n",
    "    print()\n",
    "    validateSplit(noLabelSet, labelTrainingSet, labelTestingSet, classNames)\n",
    "    print()\n",
    "\n",
    "    # Save the raw splits.\n",
    "    print('/* Saving the raw splits *\\\\')\n",
    "    saveSplits(noLabelSet, labelTrainingSet, labelTestingSet, classNames, outputPath)"
   ]
  },
  {
   "source": [
    "### First run\n",
    "- Data without labels: 80%\n",
    "- With labels (training): 10%\n",
    "- With labels (test): 10%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw dataset path\n",
    "datasetPath = 'data/raw'\n",
    "\n",
    "# Output paths\n",
    "outputPath  = 'data/corrida1'\n",
    "\n",
    "# Training percentage\n",
    "noLabelPercentage = 0.8\n",
    "labelTrainingPercentage = 0.1\n",
    "labelTestingPercentage = 0.1\n",
    "\n",
    "createSplits(datasetPath, noLabelPercentage, labelTrainingPercentage, labelTestingPercentage, outputPath)"
   ]
  },
  {
   "source": [
    "### Second run\n",
    "- Data without labels: 50%\n",
    "- With labels (training): 35%\n",
    "- With labels (test): 15%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw dataset path\n",
    "datasetPath = 'data/raw'\n",
    "\n",
    "# Output paths\n",
    "outputPath  = 'data/corrida2'\n",
    "\n",
    "# Training percentage\n",
    "noLabelPercentage = 0.5\n",
    "labelTrainingPercentage = 0.35\n",
    "labelTestingPercentage = 0.15\n",
    "\n",
    "createSplits(datasetPath, noLabelPercentage, labelTrainingPercentage, labelTestingPercentage, outputPath)"
   ]
  }
 ]
}