{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd03a31fab793c547cb35fe033c429e016f6dd189ef070db975037acd85972e51d4",
   "display_name": "Python 3.9.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "3a31fab793c547cb35fe033c429e016f6dd189ef070db975037acd85972e51d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "from os.path import isdir\n",
    "from os.path import join\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import shutil\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "import wandb"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 17,
   "outputs": []
  },
  {
   "source": [
    "Misc functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "  X = []\n",
    "  Y = []\n",
    "\n",
    "  onlyDirs = [f for f in listdir(path) if isdir(join(path, f))]\n",
    "\n",
    "  for category in onlyDirs:\n",
    "    pos_y = onlyDirs.index(category)\n",
    "    print(category, pos_y)\n",
    "    tempDirInput = join(path, category)\n",
    "    for f in listdir(tempDirInput):\n",
    "      inputPath = (join(tempDirInput, f))\n",
    "      if isfile(inputPath):\n",
    "        X.append(np.load(inputPath))\n",
    "        one_hot = np.zeros((len(onlyDirs)))\n",
    "        one_hot[pos_y] = 1\n",
    "        Y.append(one_hot)\n",
    "\n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    \n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    \n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# About metrics.\n",
    "# Metric dictionary keys \n",
    "_loss            = 'Loss'\n",
    "_accuracy        = 'Accuracy'\n",
    "_accuracyClass   = 'Accuracy class'\n",
    "_confusionMatrix = 'Confusion matrix'\n",
    "_groundtruth     = 'Groundtruth'\n",
    "_predictions     = 'Predictions'\n",
    "# Get a clean dictionary for the metrics.\n",
    "def getMetricsDict(config):\n",
    "    return {\n",
    "        _loss            : torch.tensor(0.),\n",
    "        _accuracy        : torch.tensor(0.),\n",
    "        _accuracyClass   : torch.zeros(config[classesLen]),\n",
    "        _confusionMatrix : torch.zeros((config[classesLen], config[classesLen]), dtype=torch.int),\n",
    "        _groundtruth     : torch.tensor([]),\n",
    "        _predictions     : torch.tensor([])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print the metrics dictionaries.\n",
    "def printMetricsDict(metricsResults, config):\n",
    "    # Build accuracy by class.\n",
    "    accuracyClassStr = ''\n",
    "    for i, _class in enumerate(config[classes]):\n",
    "        accuracyClassStr += '{}: {:2.2f}%'.format(_class, metricsResults[_accuracyClass][i] * 100)\n",
    "        accuracyClassStr += ', '\n",
    "    accuracyClassStr = accuracyClassStr[:-2]\n",
    "\n",
    "    print('Loss: {:.4f}, Accuracy: {:2.2f}% ({})'.format(metricsResults[_loss], metricsResults[_accuracy] * 100, accuracyClassStr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to update the dictionary of resulting metrics.\n",
    "def updateRunningMetrics(outputs, groundtruth, loss, batchAmount, metricsResults, config):\n",
    "    # Accumulate the loss.\n",
    "    metricsResults[_loss] += loss.cpu() / batchAmount\n",
    "    # Accumulate the confusion matrix.\n",
    "    confusionMatrix = getConfusionMatrix(outputs, groundtruth, config)\n",
    "    metricsResults[_confusionMatrix] += confusionMatrix\n",
    "    metricsResults[_groundtruth] = torch.cat((metricsResults[_groundtruth], groundtruth)) \n",
    "    metricsResults[_predictions] = torch.cat((metricsResults[_predictions], outputs))\n",
    "\n",
    "# Function used to process the dictionary of resulting metrics (make final calculations).\n",
    "def processRunningMetrics(metricsResults):\n",
    "    # Get the total of samples processed by class.\n",
    "    classTotal = torch.sum(metricsResults[_confusionMatrix], 1)\n",
    "    # Get the total of samples correctly classified by class.\n",
    "    classCorrect = torch.diagonal(metricsResults[_confusionMatrix])\n",
    "\n",
    "    # Get the total accuracy, correct total samples / total samples.\n",
    "    metricsResults[_accuracy] = torch.sum(classCorrect) / torch.sum(classTotal)\n",
    "    # Get the total accuracy, by class.\n",
    "    metricsResults[_accuracyClass] = classCorrect / classTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions process an metrics result dictionary for wandb. Is necessary to indicte\n",
    "#   the metrics origin, training or testing.\n",
    "def processMetricsWandb(metricsResults, config, training=False):\n",
    "    # Get the prefix to log on wandb, the keys must be different.\n",
    "    resultsType = 'training' if training else 'testing'\n",
    "\n",
    "    # All the wandb keys are based in the original metrics results keys.\n",
    "    lossKey = '{} ({})'.format(_loss, resultsType)\n",
    "    accuracyKey = '{} ({})'.format(_accuracy, resultsType)\n",
    "    accuracyClassKeys = ['{} accuracy ({})'.format(_class, resultsType) for _class in config[classes]]\n",
    "\n",
    "    confusionMatrixKey = '{} ({})'.format(_confusionMatrix, resultsType)\n",
    "    heatMap = wandb.sklearn.plot_confusion_matrix(torch.argmax(metricsResults[_groundtruth], axis=1), torch.argmax(metricsResults[_predictions], axis=1), config[classes])\n",
    "\n",
    "    # Make the dictionary for wandb and store the values.\n",
    "    wandbDict = {\n",
    "        lossKey             : metricsResults[_loss].item(),\n",
    "        accuracyKey         : metricsResults[_accuracy].item(),\n",
    "        confusionMatrixKey  : heatMap\n",
    "    }\n",
    "    for i in range(config[classesLen]):\n",
    "        wandbDict[accuracyClassKeys[i]] = metricsResults[_accuracyClass][i].item()\n",
    "\n",
    "    # Return, to log later.\n",
    "    return wandbDict\n",
    "    \n",
    "# Get the metrics dictionaries for wandb and log them.\n",
    "def logMetricsWandb(trainMetricsResults, testMetricsResults, config):\n",
    "    # Get both dictionaries for wandb.\n",
    "    wandbTrainDict = processMetricsWandb(trainMetricsResults, config, training=True)\n",
    "    wandbTestDict  = processMetricsWandb(testMetricsResults, config, training=False)\n",
    "\n",
    "    # Merge the dictionaries.\n",
    "    wandbDict = {**wandbTrainDict, **wandbTestDict}\n",
    "\n",
    "    # Log on wandb\n",
    "    wandb.log(wandbDict)"
   ]
  },
  {
   "source": [
    "# Calculate the confusion matrix.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the confusion matrix values.\n",
    "def getConfusionMatrix(outputs, groundtruth, config):\n",
    "    # Init the confusion matrix.\n",
    "    confusionMatrix = torch.zeros((config[classesLen], config[classesLen]), dtype=torch.int)\n",
    "\n",
    "    # Obtain the predictions (the greater number, because we use a one hot vector).\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Iterate the predictions.\n",
    "    for i in range(predicted.shape[0]):\n",
    "        # Add 1 based on the prediction done for a specific label.\n",
    "        \n",
    "        confusionMatrix[torch.argmax(groundtruth[i])][predicted[i]] += 1\n",
    "\n",
    "    return confusionMatrix"
   ]
  },
  {
   "source": [
    "Paths dir"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder paths\n",
    "histOutputDir = 'data/pp/hist'\n",
    "\n",
    "run_ID = 0"
   ]
  },
  {
   "source": [
    "# Load training and testing set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "COVID 0\n",
      "Lung_Opacity 1\n",
      "Normal 2\n",
      "Viral_Pneumonia 3\n",
      "COVID 0\n",
      "Lung_Opacity 1\n",
      "Normal 2\n",
      "Viral_Pneumonia 3\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = load_data(os.path.join(histOutputDir,'test'))\n",
    "X_train, y_train = load_data(os.path.join(histOutputDir,'train'))"
   ]
  },
  {
   "source": [
    "Global parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input size of the model.\n",
    "inputSize = 'inputSize'\n",
    "# Output size of the model.\n",
    "outputSize = 'outputSize'\n",
    "# Batch size.\n",
    "batchSize = 'batchSize'\n",
    "# Epochs amount.\n",
    "epochs = 'epochs'\n",
    "# Learning rate.\n",
    "learningRate = 'learningRate'\n",
    "#FC_Layer\n",
    "fc_size_1 = 'fc_size_1'\n",
    "fc_size_2 = 'fc_size_2'\n",
    "fc_size_3 = 'fc_size_3'\n",
    "fc_size_4 = 'fc_size_4'\n",
    "fc_size_5 = 'fc_size_5'\n",
    "fc_size_6 = 'fc_size_6'\n",
    "# Class names.\n",
    "classes = 'classes'\n",
    "# Number of classes to classify.\n",
    "classesLen = 'classesLen'\n",
    "name = 'name'\n",
    "\n",
    "upSampling = 'upSampling'\n",
    "\n",
    "exp_1 = {\n",
    "    epochs        :   21,\n",
    "    learningRate :   0.0001,\n",
    "    batchSize    :   32,\n",
    "    inputSize     :   256,\n",
    "    fc_size_1     :   256,\n",
    "    fc_size_2     :   128,\n",
    "    fc_size_3     :   64,\n",
    "    fc_size_4     :   32,\n",
    "    fc_size_5     :   16,\n",
    "    fc_size_6     :   8,\n",
    "    outputSize      :   4,\n",
    "    classes      : ['COVID', 'Lung Opacity', 'Normal', 'Viral Pneumonia'],\n",
    "    classesLen     : 4,\n",
    "    upSampling     : False,\n",
    "    name           : 'WithoutUpsampling_32Batch'\n",
    "}\n",
    "exp_2 = {\n",
    "    epochs        :   21,\n",
    "    learningRate :   0.0001,\n",
    "    batchSize    :   32,\n",
    "    inputSize     :   256,\n",
    "    fc_size_1     :   256,\n",
    "    fc_size_2     :   128,\n",
    "    fc_size_3     :   64,\n",
    "    fc_size_4     :   32,\n",
    "    fc_size_5     :   16,\n",
    "    fc_size_6     :   8,\n",
    "    outputSize      :   4,\n",
    "    classes      : ['COVID', 'Lung Opacity', 'Normal', 'Viral Pneumonia'],\n",
    "    classesLen     : 4,\n",
    "    upSampling     : True,\n",
    "    name           : 'WithUpsampling_32Batch'\n",
    "}\n",
    "exp_3 = {\n",
    "    epochs        :   21,\n",
    "    learningRate :   0.0001,\n",
    "    batchSize    :   16,\n",
    "    inputSize     :   256,\n",
    "    fc_size_1     :   256,\n",
    "    fc_size_2     :   128,\n",
    "    fc_size_3     :   64,\n",
    "    fc_size_4     :   32,\n",
    "    fc_size_5     :   16,\n",
    "    fc_size_6     :   8,\n",
    "    outputSize      :   4,\n",
    "    classes      : ['COVID', 'Lung Opacity', 'Normal', 'Viral Pneumonia'],\n",
    "    classesLen     : 4,\n",
    "    upSampling     : False,\n",
    "    name           : 'WithoutUpsampling_16Batch'\n",
    "}\n",
    "exp_4 = {\n",
    "    epochs        :   21,\n",
    "    learningRate :   0.0001,\n",
    "    batchSize    :   16,\n",
    "    inputSize     :   256,\n",
    "    fc_size_1     :   256,\n",
    "    fc_size_2     :   128,\n",
    "    fc_size_3     :   64,\n",
    "    fc_size_4     :   32,\n",
    "    fc_size_5     :   16,\n",
    "    fc_size_6     :   8,\n",
    "    outputSize      :   4,\n",
    "    classes      : ['COVID', 'Lung Opacity', 'Normal', 'Viral Pneumonia'],\n",
    "    classesLen     : 4,\n",
    "    upSampling     : True,\n",
    "    name           : 'WithUpsampling_16Batch'\n",
    "}\n",
    "\n",
    "configs = [exp_1, exp_2, exp_3, exp_4]"
   ]
  },
  {
   "source": [
    "## Create a Data Loader"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### UpSampling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upSamplingData(config):\n",
    "    if config[upSampling]:\n",
    "        dic_values = {}\n",
    "        weight = {}\n",
    "        for class_type in np.unique(y_train, axis=0):\n",
    "            dic_values[int(np.argmax(class_type))] = len(np.where((y_train == class_type).all(axis=1))[0])\n",
    "            weight[int(np.argmax(class_type))] = float(1.0/len(np.unique(y_train, axis=0)))/dic_values[int (np.argmax(class_type))]\n",
    "\n",
    "        print(\"dic_values\", dic_values)\n",
    "        print(\"weight\", weight)\n",
    "\n",
    "        samples_weight = np.array([weight[int(np.argmax(t))] for t in y_train])\n",
    "        samples_weight = torch.from_numpy(samples_weight)\n",
    "        sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))\n",
    "\n",
    "        return sampler\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampler option is mutually exclusive with shuffle option.\n",
    "def setShuffle(config):\n",
    "    if config[upSampling]:\n",
    "        return False\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataLoaders(config):\n",
    "        tensor_x = torch.Tensor(X_train) \n",
    "        tensor_y = torch.Tensor(y_train)\n",
    "        my_dataset = TensorDataset(tensor_x,tensor_y) \n",
    "        trainingSetLoader = DataLoader(my_dataset,\n",
    "                shuffle=setShuffle(config),\n",
    "                sampler= upSamplingData(config),\n",
    "                batch_size=config[batchSize]) \n",
    "\n",
    "        tensor_x_test = torch.Tensor(X_test) \n",
    "        tensor_y_test = torch.Tensor(y_test)\n",
    "        my_dataset_test = TensorDataset(tensor_x_test,tensor_y_test) \n",
    "        testSetLoader = DataLoader(my_dataset_test,\n",
    "                shuffle=True,\n",
    "                batch_size=config[batchSize]) \n",
    "        return (trainingSetLoader, testSetLoader)\n"
   ]
  },
  {
   "source": [
    "Check CUDA is available"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "source": [
    "## Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, config):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, config[fc_size_1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config[fc_size_1], config[fc_size_2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config[fc_size_2], config[fc_size_3]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config[fc_size_3], config[fc_size_4]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(config[fc_size_4], config[fc_size_5]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config[fc_size_5], config[fc_size_6]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config[fc_size_6], output_dim),\n",
    "            nn.Softmax(dim=1)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    "
   ]
  },
  {
   "source": [
    "### Training method.\n",
    "This method takes care of a single training pass. Another function call this one multiple times."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpoch(dataloader, model, criterion, optimizer, config):\n",
    "    # Metrics for training.\n",
    "    metricsResults = getMetricsDict(config)\n",
    "\n",
    "    # Enable the grad, for training.\n",
    "    with torch.set_grad_enabled(True):\n",
    "\n",
    "        # Indicate that the model is going to be trained.\n",
    "        model.train()\n",
    "\n",
    "        # Loader len, for metrics calculation.\n",
    "        loaderLen = len(dataloader)\n",
    "\n",
    "        # Iterate the batches for training.\n",
    "        for batch in dataloader:\n",
    "            # Train the model.\n",
    "            # Get the inputs and labels, and move them to the selected device.\n",
    "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "            # Zero the gradient parameters.\n",
    "            optimizer.zero_grad()\n",
    "            # Get the predictions.\n",
    "            outputs = model(inputs)\n",
    "            # Calculate the error.\n",
    "            labels_argmax = torch.empty(labels.shape[0], dtype=torch.long)\n",
    "            labels_argmax = torch.argmax(labels, dim=1)\n",
    "            loss = criterion(outputs, labels_argmax)\n",
    "            # Calculates the derivatives of the parameters that have a gradient.\n",
    "            loss.backward()\n",
    "            # Update the parameters based on the computer gradient.\n",
    "            optimizer.step()\n",
    "            # Metrics for the training set.\n",
    "            updateRunningMetrics(outputs, labels, loss, loaderLen, metricsResults, config)\n",
    "\n",
    "    return metricsResults"
   ]
  },
  {
   "source": [
    "### Evaluation method.\n",
    "This method evaluates the model for a specified dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, criterion, config):\n",
    "    # Metrics for testing.\n",
    "    metricsResults = getMetricsDict(config)\n",
    "\n",
    "    # Enable the grad, for training.\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        # Indicate that the model is going to be evaluated.\n",
    "        model.eval()\n",
    "\n",
    "        # Loader len, for metrics calculation.\n",
    "        loaderLen = len(dataloader)\n",
    "\n",
    "        # Iterate the batches for testing.\n",
    "        for batch in dataloader:\n",
    "            # Test the model.\n",
    "            # Get the inputs and labels, and move them to the selected device.\n",
    "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "            # Get the predictions.\n",
    "            outputs = model(inputs)\n",
    "            # Calculate the error.\n",
    "            labels_argmax = torch.empty(labels.shape[0], dtype=torch.long)\n",
    "            labels_argmax = torch.argmax(labels, dim=1)\n",
    "            loss = criterion(outputs, labels_argmax)\n",
    "            # Metrics for the testing set.\n",
    "            updateRunningMetrics(outputs, labels, loss, loaderLen, metricsResults, config)\n",
    "\n",
    "    return metricsResults"
   ]
  },
  {
   "source": [
    "### Trainining and evaluate method.\n",
    "For the specific purpose of this project, in each epoch we evaluate metrics for each data set (training and testing) in each epoch, this method simplifies the process. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndEvaluate(trainloader, testloader, model, criterion, optimizer, config):\n",
    "    startTimeTotal = time.time()\n",
    "    for epoch in range(1, config[epochs] + 1):\n",
    "        \n",
    "        # Train the model.\n",
    "        trainMetricsResults = trainEpoch(trainloader, model, criterion, optimizer, config)\n",
    "        processRunningMetrics(trainMetricsResults)\n",
    "\n",
    "        # Evaluate the model.\n",
    "        testMetricsResults = evaluate(testloader, model, criterion, config)\n",
    "        processRunningMetrics(testMetricsResults)\n",
    "\n",
    "        # Log on wandb\n",
    "        logMetricsWandb(trainMetricsResults, testMetricsResults, config)\n",
    "\n",
    "        # Print the results.\n",
    "        if epoch %20 == 0:\n",
    "            print('**', '[', 'Epoch ', epoch, ']', '*' * 48, sep='')\n",
    "            print('\\tTraining results:', end=' ')\n",
    "            printMetricsDict(trainMetricsResults)\n",
    "            print('\\t Testing results:', end=' ')\n",
    "            printMetricsDict(testMetricsResults)\n",
    "        \n",
    "    # Print time\n",
    "    print('Epochs terminados')\n",
    "    print(\"--- %s seconds ---\" % (time.time() - startTimeTotal))"
   ]
  },
  {
   "source": [
    "# Run"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:3gsndqwp) before initializing another..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 12268<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>c:\\Users\\TEC\\Documents\\GitHub\\ML\\Proyectos\\Proyecto II\\wandb\\run-20210510_140239-3gsndqwp\\logs\\debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>c:\\Users\\TEC\\Documents\\GitHub\\ML\\Proyectos\\Proyecto II\\wandb\\run-20210510_140239-3gsndqwp\\logs\\debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>_runtime</td><td>302</td></tr><tr><td>_timestamp</td><td>1620677264</td></tr><tr><td>_step</td><td>46</td></tr><tr><td>Loss (training)</td><td>1.17826</td></tr><tr><td>Accuracy (training)</td><td>0.55646</td></tr><tr><td>COVID accuracy (training)</td><td>0.0</td></tr><tr><td>Lung Opacity accuracy (training)</td><td>0.58344</td></tr><tr><td>Normal accuracy (training)</td><td>0.81202</td></tr><tr><td>Viral Pneumonia accuracy (training)</td><td>0.0</td></tr><tr><td>Loss (testing)</td><td>1.17494</td></tr><tr><td>Accuracy (testing)</td><td>0.5613</td></tr><tr><td>COVID accuracy (testing)</td><td>0.0</td></tr><tr><td>Lung Opacity accuracy (testing)</td><td>0.61028</td></tr><tr><td>Normal accuracy (testing)</td><td>0.80313</td></tr><tr><td>Viral Pneumonia accuracy (testing)</td><td>0.0</td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Loss (training)</td><td>█▅▄▄▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>Accuracy (training)</td><td>▁▅▅▅▅▆▆▇▇██████</td></tr><tr><td>COVID accuracy (training)</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Lung Opacity accuracy (training)</td><td>▇▁▁▁▂▃▄▅▆▇▇████</td></tr><tr><td>Normal accuracy (training)</td><td>▁████▇▇▇▆▆▆▆▆▆▆</td></tr><tr><td>Viral Pneumonia accuracy (training)</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss (testing)</td><td>██▇▆▄▄▄▃▃▂▂▂▁▁▁</td></tr><tr><td>Accuracy (testing)</td><td>▁▁▁▁▂▄▅▆▇▇▇████</td></tr><tr><td>COVID accuracy (testing)</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Lung Opacity accuracy (testing)</td><td>▁▁▁▁▂▃▅▅▆▇█████</td></tr><tr><td>Normal accuracy (testing)</td><td>████▇▆▅▄▃▂▁▁▁▁▁</td></tr><tr><td>Viral Pneumonia accuracy (testing)</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 33 media file(s), 29 artifact file(s) and 0 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">WithoutUpsampling_32Batch12</strong>: <a href=\"https://wandb.ai/tecai/MLP/runs/3gsndqwp\" target=\"_blank\">https://wandb.ai/tecai/MLP/runs/3gsndqwp</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "...Successfully finished last run (ID:3gsndqwp). Initializing new run:<br/><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "wandb: wandb version 0.10.30 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.29<br/>\n                Syncing run <strong style=\"color:#cdcd00\">WithoutUpsampling_32Batch13</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/tecai/MLP\" target=\"_blank\">https://wandb.ai/tecai/MLP</a><br/>\n                Run page: <a href=\"https://wandb.ai/tecai/MLP/runs/3ixszmdu\" target=\"_blank\">https://wandb.ai/tecai/MLP/runs/3ixszmdu</a><br/>\n                Run data is saved locally in <code>c:\\Users\\TEC\\Documents\\GitHub\\ML\\Proyectos\\Proyecto II\\wandb\\run-20210510_140924-3ixszmdu</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running training\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-5ef0e3c781a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#Train and evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mtrainAndEvaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunConfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;31m#Finish WandB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-943cd4eeee17>\u001b[0m in \u001b[0;36mtrainAndEvaluate\u001b[1;34m(trainloader, testloader, model, criterion, optimizer, config)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Log on wandb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mlogMetricsWandb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainMetricsResults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestMetricsResults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Print the results.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-2e1201330a21>\u001b[0m in \u001b[0;36mlogMetricsWandb\u001b[1;34m(trainMetricsResults, testMetricsResults, config)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlogMetricsWandb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainMetricsResults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestMetricsResults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Get both dictionaries for wandb.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mwandbTrainDict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessMetricsWandb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainMetricsResults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mwandbTestDict\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mprocessMetricsWandb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestMetricsResults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-2e1201330a21>\u001b[0m in \u001b[0;36mprocessMetricsWandb\u001b[1;34m(metricsResults, config, training)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mconfusionMatrixKey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{} ({})'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_confusionMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresultsType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mheatMap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetricsResults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_groundtruth\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetricsResults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_predictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Make the dictionary for wandb and store the values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sklearn\\__init__.py\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[1;34m(y_true, y_pred, labels, true_labels, pred_labels, title, normalize, hide_zeros, hide_counts)\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_probas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m     \"\"\"\n\u001b[1;32m--> 535\u001b[1;33m     wandb.log(\n\u001b[0m\u001b[0;32m    536\u001b[0m         {\n\u001b[0;32m    537\u001b[0m             \"confusion_matrix\": confusion_matrix(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\u001b[0m in \u001b[0;36mlog\u001b[1;34m(self, data, step, commit, sync)\u001b[0m\n\u001b[0;32m   1083\u001b[0m                         \u001b[1;34m\"Step must only increase in log calls.  \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m                         \"Step {} < {}; dropping {}.\".format(\n\u001b[1;32m-> 1085\u001b[1;33m                             \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1086\u001b[0m                         )\n\u001b[0;32m   1087\u001b[0m                     )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\wandb_history.py\u001b[0m in \u001b[0;36m_row_add\u001b[1;34m(self, row)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_row_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\wandb_history.py\u001b[0m in \u001b[0;36m_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"_timestamp\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_timestamp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\u001b[0m in \u001b[0;36m_history_callback\u001b[1;34m(self, row, step)\u001b[0m\n\u001b[0;32m    833\u001b[0m             \u001b[1;31m# remove the chart key from the row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;31m# TODO: is this really the right move? what if the user logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m             \u001b[1;31m#     a non-custom chart to this key?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m             \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[1;31m# add the table under a different key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\u001b[0m in \u001b[0;36mpublish_history\u001b[1;34m(self, data, step, run, publish_step)\u001b[0m\n\u001b[0;32m    215\u001b[0m     ) -> None:\n\u001b[0;32m    216\u001b[0m         \u001b[0mrun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_types\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory_dict_to_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHistoryRecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpublish_step\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\data_types.py\u001b[0m in \u001b[0;36mhistory_dict_to_json\u001b[1;34m(run, payload, step)\u001b[0m\n\u001b[0;32m   2064\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m             \u001b[0mpayload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict_to_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2066\u001b[1;33m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2067\u001b[0m             \u001b[0mpayload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_to_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\data_types.py\u001b[0m in \u001b[0;36mval_to_json\u001b[1;34m(run, key, val, namespace)\u001b[0m\n\u001b[0;32m   2138\u001b[0m                 \u001b[0mart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2139\u001b[0m                 \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2140\u001b[1;33m             \u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind_to_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2141\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\data_types.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(self, run_or_artifact)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_or_artifact\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[0mjson_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_or_artifact\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m         \u001b[0mwandb_run\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwandb_artifacts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_sdk_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\data_types.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(self, run)\u001b[0m\n\u001b[0;32m    498\u001b[0m                 }\n\u001b[0;32m    499\u001b[0m             )\n\u001b[1;32m--> 500\u001b[1;33m             \u001b[0martifact_entry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_artifact_reference_entry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martifact_entry\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m                 \u001b[0mjson_obj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"artifact_path\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0martifact_entry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\data_types.py\u001b[0m in \u001b[0;36m_get_artifact_reference_entry\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[1;31m# Currently, we do not have a way to obtain a reference URL without waiting for the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[1;31m# upstream artifact to be logged. This implies that this only works online as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_artifact_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0martifact\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m             ref_entry = self._artifact_target.artifact.get_path(\n\u001b[0;32m    260\u001b[0m                 \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_artifact_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\wandb_artifacts.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    629\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mArtifactInterface\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logged_artifact\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logged_artifact\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2457\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_assert_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mArtifactInterface\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2458\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_instance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2459\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   2460\u001b[0m                 \u001b[1;34m\"Must call wait() before accessing logged artifact properties\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2461\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mis_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object_ready\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_set\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Create the model, optimizer and criterion\n",
    "run_ID += 1\n",
    "for runConfig in configs:\n",
    "    print(\"Running\")\n",
    "    print(runConfig[name])\n",
    "    trainloader, testloader = createDataLoaders(runConfig)\n",
    "    \n",
    "    model = MLP(runConfig[inputSize], runConfig[outputSize], runConfig)\n",
    "    optimizer = optim.Adam(model.parameters(),lr=runConfig[learningRate])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    #Init WandB\n",
    "    nameRun = runConfig[name] + str(run_ID)\n",
    "    run = wandb.init(project='MLP', entity='tecai', config=runConfig,\n",
    "                            name=nameRun)\n",
    "    wandb.watch(model)\n",
    "    #Train and evaluate the model\n",
    "    trainAndEvaluate(trainloader, testloader, model, criterion, optimizer, runConfig)\n",
    "    #Finish WandB\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}