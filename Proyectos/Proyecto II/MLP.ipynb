{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "from os.path import isdir\n",
    "from os.path import join\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import shutil\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import wandb"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "source": [
    "Misc functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "  X = []\n",
    "  Y = []\n",
    "\n",
    "  onlyDirs = [f for f in listdir(path) if isdir(join(path, f))]\n",
    "\n",
    "  for category in onlyDirs:\n",
    "    pos_y = onlyDirs.index(category)\n",
    "    print(category, pos_y)\n",
    "    tempDirInput = join(path, category)\n",
    "    for f in listdir(tempDirInput):\n",
    "      inputPath = (join(tempDirInput, f))\n",
    "      if isfile(inputPath):\n",
    "        X.append(np.load(inputPath))\n",
    "        one_hot = np.zeros((len(onlyDirs)))\n",
    "        one_hot[pos_y] = 1\n",
    "        Y.append(one_hot)\n",
    "\n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    \n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    \n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "source": [
    "Paths dir"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder paths\n",
    "histOutputDir = 'data/pp/hist'\n",
    "\n",
    "run_ID = 0"
   ]
  },
  {
   "source": [
    "# Load training and testing set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "COVID 0\n",
      "Lung_Opacity 1\n",
      "Normal 2\n",
      "Viral Pneumonia 3\n",
      "COVID 0\n",
      "Lung_Opacity 1\n",
      "Normal 2\n",
      "Viral Pneumonia 3\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = load_data(os.path.join(histOutputDir,'test'))\n",
    "X_train, y_train = load_data(os.path.join(histOutputDir,'train'))"
   ]
  },
  {
   "source": [
    "Global parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "configwand = {\n",
    "    'epochs'        :   600,\n",
    "    'learning_rate' :   0.0005,\n",
    "    'batch_size'    :   128,\n",
    "    'input_dim'     :   256,\n",
    "    'fc_size_1'     :   256,\n",
    "    'fc_size_2'     :   128,\n",
    "    'fc_size_3'     :   64,\n",
    "    'fc_size_4'     :   32,\n",
    "    'fc_size_5'     :   16,\n",
    "    'fc_size_6'     :   8,\n",
    "    'output_dim'    :   4\n",
    "}"
   ]
  },
  {
   "source": [
    "## Create a Data Loader"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x = torch.Tensor(X_train) \n",
    "tensor_y = torch.Tensor(y_train)\n",
    "my_dataset = TensorDataset(tensor_x,tensor_y) \n",
    "trainingSetLoader = DataLoader(my_dataset,\n",
    "        shuffle=True,\n",
    "        batch_size=configwand['batch_size']) \n",
    "\n",
    "tensor_x_test = torch.Tensor(X_test) \n",
    "tensor_y_test = torch.Tensor(y_test)\n",
    "my_dataset_test = TensorDataset(tensor_x_test,tensor_y_test) \n",
    "testSetLoader = DataLoader(my_dataset_test,\n",
    "        shuffle=True,\n",
    "        batch_size=configwand['batch_size']) \n"
   ]
  },
  {
   "source": [
    "## Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, configwand['fc_size_1']),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(configwand['fc_size_1'], configwand['fc_size_2']),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(configwand['fc_size_2'], configwand['fc_size_3']),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(configwand['fc_size_3'], configwand['fc_size_4']),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(configwand['fc_size_4'], configwand['fc_size_5']),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(configwand['fc_size_5'], configwand['fc_size_6']),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(configwand['fc_size_6'], output_dim),\n",
    "            nn.Softmax()\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion):\n",
    "    for epoch in range(0, configwand['epochs']):\n",
    "        is_training = True\n",
    "        with torch.set_grad_enabled(is_training):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            for i_Train, (x, y) in enumerate(trainingSetLoader):\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                y_pred = model(x)\n",
    "                y_argmax = torch.empty(y.shape[0], dtype=torch.long)\n",
    "                y_argmax = torch.argmax(y, dim=1)\n",
    "                loss = criterion(y_pred, y_argmax)\n",
    "                \n",
    "                acc = calculate_accuracy(y_pred, y_argmax)\n",
    "                loss.backward()\n",
    "        \n",
    "                running_loss += loss.item()\n",
    "                running_acc += acc\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        is_training = False\n",
    "\n",
    "        running_test_loss = 0.0\n",
    "        running_test_acc = 0.0\n",
    "\n",
    "        with torch.set_grad_enabled(is_training):\n",
    "            for i_Test, (x, y) in enumerate(testSetLoader):\n",
    "                \n",
    "                y_pred = model(x)\n",
    "                y_argmax = torch.empty(y.shape[0], dtype=torch.long)\n",
    "                y_argmax = torch.argmax(y, dim=1)\n",
    "\n",
    "                loss = criterion(y_pred, y_argmax)\n",
    "                acc = calculate_accuracy(y_pred, y_argmax)\n",
    "        \n",
    "                running_test_loss += loss.item()\n",
    "                running_test_acc += acc\n",
    "\n",
    "        \n",
    "        wandb.log({\"Training Loss\"       :  running_loss/i_Train})\n",
    "        wandb.log({\"Training Accuracy\"   :  running_acc/i_Train})\n",
    "\n",
    "        wandb.log({\"Test Loss\"       :  running_test_loss/i_Test})\n",
    "        wandb.log({\"Test Accuracy\"   :  running_test_acc/i_Test})\n",
    "\n",
    "        if(epoch%20 == 0):\n",
    "            print(\"Epoch %d, training loss: {%.3f}, training acc {%.3f}\" % (epoch, \n",
    "                    running_loss/i_Train, running_acc/i_Train))\n",
    "            print(\"Epoch %d, testing loss: {%.3f}, testing acc {%.3f}\" % (epoch, \n",
    "                    running_test_loss/i_Test, running_test_acc/i_Test))\n",
    "            print('******************************************')\n"
   ]
  },
  {
   "source": [
    "# Run"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "run_ID += 1\n",
    "print(run_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:1j8o78yj) before initializing another..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 2420<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>c:\\Users\\Steven\\Documents\\Github\\ML\\Proyectos\\Proyecto II\\wandb\\run-20210506_122155-1j8o78yj\\logs\\debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>c:\\Users\\Steven\\Documents\\Github\\ML\\Proyectos\\Proyecto II\\wandb\\run-20210506_122155-1j8o78yj\\logs\\debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>Loss</td><td>1.17613</td></tr><tr><td>_runtime</td><td>14</td></tr><tr><td>_timestamp</td><td>1620325329</td></tr><tr><td>_step</td><td>21</td></tr><tr><td>Accuracy</td><td>0.5714</td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>Loss</td><td>█▅▄▄▄▃▂▂▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▂▂▃▃▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▃▃▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>Accuracy</td><td>▁▄▄▅▄▅▇▇▇▇█</td></tr></table><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">MLP 2</strong>: <a href=\"https://wandb.ai/stevenpach10/MLP/runs/1j8o78yj\" target=\"_blank\">https://wandb.ai/stevenpach10/MLP/runs/1j8o78yj</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "...Successfully finished last run (ID:1j8o78yj). Initializing new run:<br/><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.29<br/>\n                Syncing run <strong style=\"color:#cdcd00\">MLP 3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/stevenpach10/MLP\" target=\"_blank\">https://wandb.ai/stevenpach10/MLP</a><br/>\n                Run page: <a href=\"https://wandb.ai/stevenpach10/MLP/runs/1vzmhmez\" target=\"_blank\">https://wandb.ai/stevenpach10/MLP/runs/1vzmhmez</a><br/>\n                Run data is saved locally in <code>c:\\Users\\Steven\\Documents\\Github\\ML\\Proyectos\\Proyecto II\\wandb\\run-20210506_122212-1vzmhmez</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0, loss: {1.368}, acc {0.332}\n",
      "******************************************\n",
      "Epoch 20, loss: {1.151}, acc {0.602}\n",
      "******************************************\n",
      "Epoch 40, loss: {1.121}, acc {0.630}\n",
      "******************************************\n",
      "Epoch 60, loss: {1.114}, acc {0.638}\n",
      "******************************************\n",
      "Epoch 80, loss: {1.107}, acc {0.646}\n",
      "******************************************\n",
      "Epoch 100, loss: {1.095}, acc {0.659}\n",
      "******************************************\n",
      "Epoch 120, loss: {1.091}, acc {0.663}\n",
      "******************************************\n",
      "Epoch 140, loss: {1.083}, acc {0.673}\n",
      "******************************************\n",
      "Epoch 160, loss: {1.081}, acc {0.674}\n",
      "******************************************\n",
      "Epoch 180, loss: {1.075}, acc {0.681}\n",
      "******************************************\n",
      "Epoch 200, loss: {1.075}, acc {0.680}\n",
      "******************************************\n",
      "Epoch 220, loss: {1.066}, acc {0.690}\n",
      "******************************************\n",
      "Epoch 240, loss: {1.064}, acc {0.691}\n",
      "******************************************\n",
      "Epoch 260, loss: {1.057}, acc {0.698}\n",
      "******************************************\n",
      "Epoch 280, loss: {1.055}, acc {0.700}\n",
      "******************************************\n",
      "Epoch 300, loss: {1.045}, acc {0.710}\n",
      "******************************************\n",
      "Epoch 320, loss: {1.044}, acc {0.712}\n",
      "******************************************\n",
      "Epoch 340, loss: {1.036}, acc {0.719}\n",
      "******************************************\n",
      "Epoch 360, loss: {1.028}, acc {0.727}\n",
      "******************************************\n",
      "Epoch 380, loss: {1.021}, acc {0.734}\n",
      "******************************************\n",
      "Epoch 400, loss: {1.020}, acc {0.736}\n",
      "******************************************\n",
      "Epoch 420, loss: {1.017}, acc {0.739}\n",
      "******************************************\n",
      "Epoch 440, loss: {1.014}, acc {0.743}\n",
      "******************************************\n",
      "Epoch 460, loss: {1.005}, acc {0.751}\n",
      "******************************************\n",
      "Epoch 480, loss: {1.004}, acc {0.751}\n",
      "******************************************\n",
      "Epoch 500, loss: {0.998}, acc {0.758}\n",
      "******************************************\n",
      "Epoch 520, loss: {0.997}, acc {0.760}\n",
      "******************************************\n",
      "Epoch 540, loss: {0.992}, acc {0.764}\n",
      "******************************************\n",
      "Epoch 560, loss: {0.992}, acc {0.764}\n",
      "******************************************\n",
      "Epoch 580, loss: {0.987}, acc {0.769}\n",
      "******************************************\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 1992<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>c:\\Users\\Steven\\Documents\\Github\\ML\\Proyectos\\Proyecto II\\wandb\\run-20210506_122212-1vzmhmez\\logs\\debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>c:\\Users\\Steven\\Documents\\Github\\ML\\Proyectos\\Proyecto II\\wandb\\run-20210506_122212-1vzmhmez\\logs\\debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>Loss</td><td>0.98742</td></tr><tr><td>_runtime</td><td>636</td></tr><tr><td>_timestamp</td><td>1620325971</td></tr><tr><td>_step</td><td>1199</td></tr><tr><td>Accuracy</td><td>0.76799</td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>Loss</td><td>█▇▆▅▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Accuracy</td><td>▁▂▃▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇███████</td></tr></table><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">MLP 3</strong>: <a href=\"https://wandb.ai/stevenpach10/MLP/runs/1vzmhmez\" target=\"_blank\">https://wandb.ai/stevenpach10/MLP/runs/1vzmhmez</a><br/>\n                "
     },
     "metadata": {}
    }
   ],
   "source": [
    "#Create the model, optimizer and criterion\n",
    "run_ID += 1\n",
    "model = MLP(configwand['input_dim'], configwand['output_dim'])\n",
    "optimizer = optim.Adam(model.parameters(),lr=configwand['learning_rate'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Init WandB\n",
    "name = \"MLP \"+ str(run_ID)\n",
    "run = wandb.init(project='MLP', entity='stevenpach10', config=configwand,\n",
    "                        name=name)\n",
    "wandb.watch(model)\n",
    "#Train the model\n",
    "train(model,optimizer,criterion)\n",
    "#Finish WandB\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}