{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd009cf3d5909f3828bf53c46564821f879a9c8405e40e27fb09b54d745264e4a6d",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw dataset path\n",
    "datasetPath = 'data/Crudo'\n",
    "\n",
    "# Training percentage\n",
    "trainPercentage = 0.8\n",
    "\n",
    "# Output paths\n",
    "baseDir = 'data/raw'"
   ]
  },
  {
   "source": [
    "### Misc funnctions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to validate the distribution of the split.\n",
    "def validateSplit(trainSet, testSet, classNames):\n",
    "    classAmount = len(classNames)\n",
    "\n",
    "    # Arrays to store the amount of samples of each class.\n",
    "    trainSetDist = np.array([0] * classAmount)\n",
    "    testSetDist  = np.array([0] * classAmount)\n",
    "\n",
    "    # Count the samples of each class in the training set.\n",
    "    for train in trainSet:\n",
    "        trainSetDist[train[1]] += 1\n",
    "\n",
    "    # Count the samples of each class in the testing set.\n",
    "    for test in testSet:\n",
    "        testSetDist[test[1]] += 1\n",
    "\n",
    "    # Make the distribution vector (percentages of each class).\n",
    "    trainSetProb = trainSetDist / len(trainSet) * 100\n",
    "    testSetProb  = testSetDist  / len(testSet)  * 100\n",
    "\n",
    "    # Print the data\n",
    "    print('Training set class distribution:')\n",
    "    for i in range(classAmount):\n",
    "        print('\\t{0}: {1} ({2:2.2f}%)'.format(classNames[i], trainSetDist[i], trainSetProb[i]))\n",
    "\n",
    "    print('Testing set class distribution:')\n",
    "    for i in range(classAmount):\n",
    "        print('\\t{0}: {1} ({2:2.2f}%)'.format(classNames[i], testSetDist[i], testSetProb[i]))\n",
    "\n",
    "# Function used to save a split based on a type (training or testing).\n",
    "def saveSplit(dataset, classNames, setType, path):\n",
    "    # Get the dir for each class.\n",
    "    dirs = [os.path.join(os.getcwd(), path, setType, className) for className in classNames]\n",
    "\n",
    "    # Make the dirs.\n",
    "    for _dir in dirs:\n",
    "        Path(_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Array for control the name of the files.\n",
    "    classCounter = [0, 0, 0, 0]\n",
    "\n",
    "    # For printing the progress.\n",
    "    samplesProcessed = 0\n",
    "    samplesStep = 25\n",
    "    step = len(dataset) // 4\n",
    "\n",
    "    # Each set can be iterated getting tuples of (PIL image, label).\n",
    "    for sample in dataset:\n",
    "        # Unpack the sample.\n",
    "        (image, label) = sample\n",
    "        # Save the image in the corresponding dir.\n",
    "        image.save(os.path.join(dirs[label], str(classCounter[label]) + '.png'))\n",
    "        # Increment the counter.\n",
    "        classCounter[label] += 1\n",
    "        \n",
    "        # Progress printing.\n",
    "        samplesProcessed += 1\n",
    "        if (samplesProcessed % step == 0):\n",
    "            print('\\t' + str(samplesStep) + '% saved.')\n",
    "            samplesStep += 25\n",
    "\n",
    "# Function used to save the splits.\n",
    "def saveTrainTestSplit(trainSet, testSet, classNames, path):\n",
    "    # Save the training set.\n",
    "    print('Saving training set')\n",
    "    saveSplit(trainSet, classNames, 'train', path)\n",
    "    print()\n",
    "\n",
    "    print('Saving testing set')\n",
    "    # Save the testing set.\n",
    "    saveSplit(testSet,  classNames, 'test',  path)"
   ]
  },
  {
   "source": [
    "### Split data\n",
    "Function to get the raw data and separate them in a training/testing set and save them. In order to maintain the same sets for all the experiments."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(datasetPath, trainPercentage, save):\n",
    "    # Get the raw dataset.\n",
    "    dataset = ImageFolder(datasetPath)\n",
    "    classNames = dataset.classes\n",
    "\n",
    "    # Get the size of the training set and the testing set.\n",
    "    trainLen = int(len(dataset) * 0.8)\n",
    "    testLen  = len(dataset) - trainLen\n",
    "\n",
    "    print('Len of the dataset:', len(dataset))\n",
    "    print('\\tTraining set: {0} ({1:2.2f}%)'.format(trainLen, trainLen / len(dataset) * 100))\n",
    "    print('\\tTesting set: {0} ({1:2.2f}%)'.format(testLen,  testLen  / len(dataset) * 100))\n",
    "    print()\n",
    "\n",
    "    # Random split the general dataset.\n",
    "    trainSet, testSet = random_split(dataset, [trainLen, testLen])\n",
    "\n",
    "    # Validate the splits.\n",
    "    validateSplit(trainSet, testSet, classNames)\n",
    "    print()\n",
    "\n",
    "    # Save the splits.\n",
    "    if save:\n",
    "        saveTrainTestSplit(trainSet, testSet, classNames, baseDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Len of the dataset: 21165\n",
      "\tTraining set: 16932 (80.00%)\n",
      "\tTesting set: 4233 (20.00%)\n",
      "\n",
      "Training set class distribution:\n",
      "\tCOVID: 2906 (17.16%)\n",
      "\tLung_Opacity: 4795 (28.32%)\n",
      "\tNormal: 8158 (48.18%)\n",
      "\tViral_Pneumonia: 1073 (6.34%)\n",
      "Testing set class distribution:\n",
      "\tCOVID: 710 (16.77%)\n",
      "\tLung_Opacity: 1217 (28.75%)\n",
      "\tNormal: 2034 (48.05%)\n",
      "\tViral_Pneumonia: 272 (6.43%)\n",
      "\n",
      "Saving training set\n",
      "\t25% saved.\n",
      "\t50% saved.\n",
      "\t75% saved.\n",
      "\t100% saved.\n",
      "\n",
      "Saving testing set\n",
      "\t25% saved.\n",
      "\t50% saved.\n",
      "\t75% saved.\n",
      "\t100% saved.\n"
     ]
    }
   ],
   "source": [
    "splitDataset(datasetPath, trainPercentage, True)"
   ]
  }
 ]
}